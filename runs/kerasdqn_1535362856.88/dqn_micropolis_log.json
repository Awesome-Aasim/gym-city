{"episode_reward": [6.0, 41.0, 6.0, 6.0, 17.0, 19.0, 12.0, 7.0, 6.0], "nb_steps": [1001, 2002, 3003, 4004, 5005, 6006, 7007, 8008, 9009], "mean_absolute_error": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "loss": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "mean_eps": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "nb_episode_steps": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "duration": [3.322287082672119, 3.0392420291900635, 3.1379008293151855, 2.9260079860687256, 3.072558879852295, 2.869434118270874, 3.1636970043182373, 3.020707845687866, 3.142598867416382], "episode": [0, 1, 2, 3, 4, 5, 6, 7, 8], "mean_q": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]}