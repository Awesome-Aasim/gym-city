{"episode_reward": [13.0], "nb_steps": [1001], "mean_absolute_error": [NaN], "loss": [NaN], "mean_eps": [NaN], "nb_episode_steps": [1001], "duration": [2.0571789741516113], "episode": [0], "mean_q": [NaN]}