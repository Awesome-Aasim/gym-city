{"episode_reward": [11.0, 14.0, 13.0, 17.0, 5.0, 16.0, 11.0, 17.0, 5.0, 11.0, 4.0, 25.0, 27.0], "nb_steps": [1001, 2002, 3003, 4004, 5005, 6006, 7007, 8008, 9009, 10010, 11011, 12012, 13013], "mean_absolute_error": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "loss": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "mean_eps": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN], "nb_episode_steps": [1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001, 1001], "duration": [3.170042037963867, 2.820937156677246, 2.66682505607605, 2.6191651821136475, 2.6714320182800293, 2.614280939102173, 2.7257559299468994, 2.6683108806610107, 2.592142105102539, 2.6120359897613525, 2.688380002975464, 2.6223771572113037, 2.652209997177124], "episode": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "mean_q": [NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN, NaN]}