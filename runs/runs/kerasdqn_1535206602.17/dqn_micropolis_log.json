{"episode_reward": [0.0], "nb_steps": [1001], "mean_absolute_error": [NaN], "loss": [NaN], "mean_eps": [NaN], "nb_episode_steps": [1001], "duration": [2.2546119689941406], "episode": [0], "mean_q": [NaN]}